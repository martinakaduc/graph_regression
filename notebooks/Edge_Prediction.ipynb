{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eb6064ba-1609-4771-9561-e092dead3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util \n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Callable, Tuple, Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing, NNConv, CGConv, GINEConv\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.inits import reset, zeros\n",
    "from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader, ClusterData, ClusterLoader\n",
    "from torch_geometric.utils import from_networkx, to_networkx\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "DATA_FOLDER = \"./data\"\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# torch.backends.cudnn.deterministic=True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "32a7c44f-6177-4ad6-b498-c50943ea620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bigLITTLE_graph(data_folder, no_duplicate=False, unobserved=0.0, unobserved_edge=0.0):\n",
    "    list_files = os.listdir(data_folder)\n",
    "    list_files = list(filter(lambda x: x.endswith(\".pkl\"), list_files))\n",
    "    list_labels = pickle.load(open(\"labels.pkl\", \"rb\"))\n",
    "    \n",
    "    dict_graph_size = defaultdict(lambda: [])\n",
    "    set_cycle_size = set([])\n",
    "    set_branch_size = set([])\n",
    "    \n",
    "    # Directed or Undirected? Edge weights?\n",
    "    bigLITTLE_graph = nx.DiGraph()\n",
    "    gid = 0\n",
    "    \n",
    "    for gf in list_files:\n",
    "        idx, cycle_size, branch_size, _ = gf.split(\"_\")\n",
    "        cycle_size = int(cycle_size)\n",
    "        branch_size = int(branch_size)\n",
    "        \n",
    "        if no_duplicate and len(dict_graph_size[(cycle_size, branch_size)]) > 0:\n",
    "            continue\n",
    "            \n",
    "        # graph = nx.read_gpickle(os.path.join(DATA_FOLDER, gf))\n",
    "        \n",
    "        # For testing\n",
    "        # if cycle_size > 5 or branch_size > 2:\n",
    "        #     continue\n",
    "        \n",
    "        bigLITTLE_graph.add_node(gid, features=[float(cycle_size), float(branch_size)], label=list_labels[int(idx)])\n",
    "        dict_graph_size[(cycle_size, branch_size)].append(gid)\n",
    "        \n",
    "        set_cycle_size.add(cycle_size)\n",
    "        set_branch_size.add(branch_size)\n",
    "        gid += 1\n",
    "        \n",
    "    # Same cycle size & Different branch size ==> Edge: [0, 1]\n",
    "    # Filter lists of same cycle_size\n",
    "    for cs in set_cycle_size:\n",
    "        list_same_cycle_size = list(filter(lambda x: x[0]==cs, dict_graph_size.keys()))\n",
    "        list_same_cycle_size = list(sorted(list_same_cycle_size, key=lambda x:x[1]))\n",
    "        # print(list_same_cycle_size)\n",
    "        for bs_idx1 in range(len(list_same_cycle_size)-1):\n",
    "            bs_idx2 = bs_idx1 + 1\n",
    "            key_cb1 = list_same_cycle_size[bs_idx1] # e.g. (3, 1)\n",
    "            key_cb2 = list_same_cycle_size[bs_idx2] # e.g. (3, 2)\n",
    "\n",
    "            for gid1 in dict_graph_size[key_cb1]:\n",
    "                for gid2 in dict_graph_size[key_cb2]:\n",
    "                    # print(key_cb2[1]-key_cb1[1])\n",
    "                    bigLITTLE_graph.add_edge(gid1, gid2, e=[0,1])\n",
    "                    bigLITTLE_graph.add_edge(gid2, gid1, e=[0,-1])\n",
    "                        \n",
    "    # Different cycle size & Same branch size ==> Edge: [1, 0]\n",
    "    for bs in set_branch_size:\n",
    "        list_same_branch_size = list(filter(lambda x: x[1]==bs, dict_graph_size.keys()))\n",
    "        list_same_branch_size = list(sorted(list_same_branch_size, key=lambda x:x[0]))\n",
    "        \n",
    "        for cs_idx1 in range(len(list_same_branch_size)-1):\n",
    "            cs_idx2 = cs_idx1 + 1\n",
    "            key_cb1 = list_same_branch_size[cs_idx1] # e.g. (3, 1)\n",
    "            key_cb2 = list_same_branch_size[cs_idx2] # e.g. (4, 1)\n",
    "\n",
    "            for gid1 in dict_graph_size[key_cb1]:\n",
    "                for gid2 in dict_graph_size[key_cb2]:\n",
    "                    bigLITTLE_graph.add_edge(gid1, gid2, e=[1,0])\n",
    "                    bigLITTLE_graph.add_edge(gid2, gid1, e=[-1,0])\n",
    "                    \n",
    "    \n",
    "    # Add all other edge as [0,0]\n",
    "    list_nodes = list(bigLITTLE_graph.nodes)\n",
    "    for i in range(len(list_nodes)):\n",
    "        for j in range(i, len(list_nodes)):\n",
    "            nid_i = list_nodes[i]\n",
    "            nid_j = list_nodes[j]\n",
    "            if not bigLITTLE_graph.has_edge(nid_i, nid_j):\n",
    "                bigLITTLE_graph.add_edge(gid1, gid2, e=[0,0])\n",
    "                bigLITTLE_graph.add_edge(gid2, gid1, e=[0,0])\n",
    "            \n",
    "    if unobserved_edge > 0:\n",
    "        # Remove unobserved edges\n",
    "        \n",
    "        num_edge_to_remove = int(bigLITTLE_graph.number_of_edges() * unobserved_edge)\n",
    "            \n",
    "        list_edges = np.array([list(e) for e in bigLITTLE_graph.edges])\n",
    "        # >>> n_edges * 2\n",
    "        list_unique_edges = list_edges[list_edges[:,1] >= list_edges[:,0]]\n",
    "        edge_idxs = np.random.choice([0,1], \n",
    "                                size=list_unique_edges.shape[0], \n",
    "                                p=[unobserved_edge, 1-unobserved_edge])\n",
    "        list_remove_edges = list_unique_edges[edge_idxs==0]\n",
    "        \n",
    "        for edge in list_remove_edges:\n",
    "            u, v = edge\n",
    "            bigLITTLE_graph.remove_edge(u,v)\n",
    "            bigLITTLE_graph.remove_edge(v,u)\n",
    "        \n",
    "        return bigLITTLE_graph, []\n",
    "    \n",
    "    return bigLITTLE_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e5ba9eaa-c556-4eca-9547-d30beeaffb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_color(e):\n",
    "    if e == [0,1]:\n",
    "        return \"black\"\n",
    "    elif e == [0,-1]:\n",
    "        return \"red\"\n",
    "    elif e == [1,0]:\n",
    "        return \"green\"\n",
    "    elif e == [-1,0]:\n",
    "        return \"blue\"\n",
    "    else:\n",
    "        return \"yellow\"\n",
    "    \n",
    "def draw_graph(graph):\n",
    "    nodeLabels = {nid:graph.nodes[nid][\"label\"] for nid in graph.nodes}\n",
    "    nodeColors = \"grey\"\n",
    "    edgeColor = [get_edge_color(graph.edges[eid][\"e\"])for eid in graph.edges]\n",
    "\n",
    "    nx.draw(graph, nx.kamada_kawai_layout(graph), edge_color=edgeColor, width=1, linewidths=0.1,\n",
    "              node_size=500, node_color=nodeColors, alpha=0.9,\n",
    "              labels=nodeLabels)\n",
    "    \n",
    "def transform_func(graph, unobserved_edge_mask=None):\n",
    "    graph.x = graph.x.to(\"cuda:0\")\n",
    "    graph.edge_index = graph.edge_index.to(\"cuda:0\")\n",
    "    graph.edge_attr = graph.edge_attr.to(\"cuda:0\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fd9c2c35-c716-4d6e-a687-5fa6b0bea976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrickyActivation(nn.Module):\n",
    "    def __init__(self, low = -1, high=1, inplace=False):\n",
    "        super().__init__()\n",
    "        self.low = -1\n",
    "        self.high = 1\n",
    "        self.zero = torch.zeros(1).to(\"cuda:0\")\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, e):\n",
    "        # F.threshold: y = x if x > theshold else default_value\n",
    "        e = F.threshold(e, self.low, 0, self.inplace)\n",
    "        e = -e\n",
    "        e = F.threshold(e, -self.high, 0, self.inplace)\n",
    "        e = -e\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "968b85d1-7f75-4a5d-803f-5a56bec6187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, node_channels, edge_channels, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.node_embed = nn.Linear(node_channels, hidden_channels, bias=False)\n",
    "        \n",
    "        self.lin1 = nn.Linear(node_channels, hidden_channels, bias=True)\n",
    "        self.lin2 = nn.Linear(hidden_channels, edge_channels, bias=True)\n",
    "        self.out_act = TrickyActivation()\n",
    "\n",
    "    def forward(self, x, observed_edge_nid, batch):\n",
    "        \n",
    "        '''\n",
    "        x: (num_nodes, 2)\n",
    "        observed_edge_nid: (num_observed_edge, 2)\n",
    "        '''\n",
    "        # 1. Obtain node embeddings\n",
    "        z = self.node_embed(x)\n",
    "        z = z.relu()\n",
    "        \n",
    "        # 2. Apply a final classifier\n",
    "        # z = F.dropout(z, p=0.1, training=True)\n",
    "        \n",
    "        # observed_edge_nid: [(1,2), (3,4)] ==> (x[1] <-> x[2])\n",
    "        # (40.1 30.1) ==> e:[1,0]\n",
    "        # (50.1 70.1) ==> e:[2,0]\n",
    "        head = x[observed_edge_nid[1]]\n",
    "        tail = x[observed_edge_nid[0]]\n",
    "        \n",
    "        e = head - tail\n",
    "        e = self.lin1(e)\n",
    "        e = self.lin2(e)\n",
    "        return e\n",
    "    \n",
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "\n",
    "    # Iterate in batches over the training dataset\n",
    "    for data in loader:\n",
    "        # Perform a single forward pass\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(\n",
    "            out, \n",
    "            data.edge_attr\n",
    "        )\n",
    "        total_loss += loss\n",
    "        \n",
    "        loss.backward(); optimizer.step(); optimizer.zero_grad(); steps += 1\n",
    "\n",
    "    return total_loss / steps\n",
    "\n",
    "def test(loader, mc_dropout_sample=100):\n",
    "    model.eval()\n",
    "    mse = 0\n",
    "    steps = 0\n",
    "\n",
    "    # Iterate in batches over the training/test dataset\n",
    "    for data in loader:\n",
    "        \n",
    "        out = []\n",
    "        for _ in range(mc_dropout_sample):\n",
    "            out.append(model(data.x, data.edge_index, data.batch))\n",
    "        out = torch.stack(out)\n",
    "        \n",
    "        # Check against ground-truth labels\n",
    "        mse += criterion(out.mean(0), data.edge_attr)\n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        \n",
    "        # out_std = out.std(0)\n",
    "    return mse / steps  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ba93a099-6a40-4738-8f0b-420f60949518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n",
      "Done!\n",
      "Computing METIS partitioning...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "generate_data = True\n",
    "unobserved_fraction = 0.2\n",
    "\n",
    "if generate_data:\n",
    "    bL_graph_train, unobserved_edge_mask = construct_bigLITTLE_graph(DATA_FOLDER, unobserved_edge=unobserved_fraction)\n",
    "    # draw_graph(bL_graph_train)\n",
    "    \n",
    "    data_train = from_networkx(bL_graph_train)\n",
    "    data_train.x = data_train.features.type(torch.FloatTensor)\n",
    "    data_train.edge_attr = data_train.e.type(torch.FloatTensor)\n",
    "    data_train = transform_func(data_train, unobserved_edge_mask)\n",
    "    \n",
    "    c_data_train = ClusterData(data_train, num_parts=1)\n",
    "    train_loader = ClusterLoader(c_data_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bL_graph_test = construct_bigLITTLE_graph(DATA_FOLDER)\n",
    "    # draw_graph(bL_graph)\n",
    "    \n",
    "    data_test = from_networkx(bL_graph_test)\n",
    "    data_test.x = data_test.features.type(torch.FloatTensor)\n",
    "    data_test.edge_attr = data_test.e.type(torch.FloatTensor)\n",
    "    data_test = transform_func(data_test)\n",
    "    \n",
    "    c_data_test = ClusterData(data_test, num_parts=1)\n",
    "    test_loader = ClusterLoader(c_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d698aab9-8c37-4372-a748-0ca318c00778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:22<00:00, 494.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100000, Train MAE: 0.0012, Test MAE: 0.0011, Min MAE: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_mse = 1e10\n",
    "min_epoch = 0\n",
    "epochs = 100000\n",
    "lr = 0.0005\n",
    "device = \"cuda:0\"\n",
    "hidden_channels = 64\n",
    "\n",
    "model = GNN(node_channels=2, edge_channels=2, \n",
    "            hidden_channels=hidden_channels).to(device)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(model)\n",
    "print(\"Number of parameters: \", params)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_mse = train(train_loader)\n",
    "    \n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        clear_output(wait=True)\n",
    "        test_mse = test(test_loader)\n",
    "        if test_mse < min_mse:\n",
    "            min_mse = test_mse\n",
    "            min_epoch = epoch\n",
    "        print(f'Epoch: {epoch+1:03d}, Train MAE: {train_mse:.4f},',\n",
    "              f'Test MAE: {test_mse:.4f}, Min MAE: {min_mse:.4f}')\n",
    "    else: test_mse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62784b-2f27-493f-a9f1-865a60f3a920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc15f7-21df-48d5-93da-6dcba369c3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
